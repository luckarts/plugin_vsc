# üìã Task 002: Stockage vectoriel de base

## üéØ Comportement attendu (Langage m√©tier)

**En tant qu'utilisateur du syst√®me Memory V2, je veux que mes m√©moires soient stock√©es avec leurs repr√©sentations vectorielles pour permettre une recherche s√©mantique rapide et pr√©cise, m√™me quand je ne me souviens pas des mots exacts utilis√©s.**

## üìù Sp√©cifications d√©taill√©es

### Comportement principal
1. **Stockage des embeddings**
   - Chaque m√©moire est automatiquement convertie en embedding vectoriel
   - Les embeddings sont stock√©s de mani√®re persistante
   - Les m√©tadonn√©es sont associ√©es aux vecteurs pour le filtrage
   - Le syst√®me g√®re les mises √† jour d'embeddings

2. **Recherche par similarit√©**
   - Recherche des m√©moires les plus similaires √† une requ√™te
   - Calcul de scores de similarit√© (cosinus, euclidienne)
   - Filtrage par m√©tadonn√©es combin√© √† la similarit√©
   - Pagination et limitation des r√©sultats

3. **Persistance et performance**
   - Les donn√©es survivent aux red√©marrages du syst√®me
   - Indexation optimis√©e pour des recherches rapides
   - Gestion de la m√©moire pour de gros volumes
   - Sauvegarde et restauration des index

## üîß Interface du Vector Store

### M√©thodes principales

#### `store(memory: Memory): Promise<void>`
**Description**: Stocker une m√©moire avec son embedding
**Comportement**:
- G√©n√®re l'embedding du contenu de la m√©moire
- Stocke le vecteur avec les m√©tadonn√©es
- Met √† jour l'index de recherche
- G√®re les erreurs de g√©n√©ration d'embedding

#### `search(query: string, options: SearchOptions): Promise<SearchResult[]>`
**Description**: Rechercher des m√©moires par similarit√© s√©mantique
**Param√®tres**:
- `query`: Texte de recherche
- `options`: Filtres et param√®tres de recherche

**Comportement**:
- G√©n√®re l'embedding de la requ√™te
- Calcule la similarit√© avec tous les vecteurs stock√©s
- Applique les filtres de m√©tadonn√©es
- Retourne les r√©sultats tri√©s par pertinence

#### `update(memoryId: string, memory: Memory): Promise<void>`
**Description**: Mettre √† jour une m√©moire existante
**Comportement**:
- R√©g√©n√®re l'embedding si le contenu a chang√©
- Met √† jour les m√©tadonn√©es
- Pr√©serve l'historique si configur√©

#### `delete(memoryId: string): Promise<void>`
**Description**: Supprimer une m√©moire du store
**Comportement**:
- Supprime le vecteur et les m√©tadonn√©es
- Met √† jour l'index
- Lib√®re l'espace de stockage

#### `getStats(): Promise<VectorStoreStats>`
**Description**: Obtenir les statistiques du store
**Retour**:
- Nombre total de vecteurs
- Taille de l'index
- M√©triques de performance
- Utilisation de la m√©moire

## üèóÔ∏è Structure des donn√©es

### Memory avec embedding
```typescript
interface StoredMemory {
  id: string
  content: string
  embedding: number[]
  metadata: MemoryMetadata
  created: Date
  updated: Date
  embeddingModel: string
  embeddingVersion: string
}

interface MemoryMetadata {
  type: MemoryType
  tags: string[]
  project?: string
  language?: string
  importance: number
  category: string
  source: string
}
```

### Options de recherche
```typescript
interface SearchOptions {
  limit?: number
  threshold?: number
  filters?: MetadataFilters
  includeEmbeddings?: boolean
  sortBy?: 'similarity' | 'date' | 'importance'
}

interface MetadataFilters {
  type?: MemoryType[]
  tags?: string[]
  project?: string
  language?: string
  dateRange?: { from: Date; to: Date }
  importance?: { min: number; max: number }
}
```

### R√©sultats de recherche
```typescript
interface SearchResult {
  memory: StoredMemory
  similarity: number
  rank: number
  explanation?: string
}

interface VectorStoreStats {
  totalVectors: number
  indexSize: number
  averageSearchTime: number
  memoryUsage: number
  embeddingModel: string
  lastOptimization: Date
}
```

## ‚öôÔ∏è Configuration

### Configuration du Vector Store
```json
{
  "vectorStore": {
    "provider": "chroma",
    "dimensions": 384,
    "similarity": "cosine",
    "indexType": "hnsw",
    "storageDir": "./data/vectors",
    "maxVectors": 100000,
    "batchSize": 100
  },
  "embedding": {
    "model": "sentence-transformers/all-MiniLM-L6-v2",
    "provider": "local",
    "cacheSize": 1000,
    "timeout": 5000
  },
  "search": {
    "defaultLimit": 10,
    "maxLimit": 100,
    "defaultThreshold": 0.7,
    "enableFilters": true
  }
}
```

## ‚úÖ Crit√®res d'acceptation

### Fonctionnels
1. **Stockage persistant**: Les embeddings survivent aux red√©marrages
2. **Recherche s√©mantique**: Trouve des m√©moires similaires m√™me avec des mots diff√©rents
3. **Performance**: Recherche < 100ms pour 1000 m√©moires
4. **Filtrage**: Combine similarit√© et filtres de m√©tadonn√©es
5. **Gestion d'erreurs**: G√®re les √©checs de g√©n√©ration d'embeddings
6. **Mise √† jour**: Met √† jour les embeddings quand le contenu change

### Non-fonctionnels
1. **Scalabilit√©**: Support de 10,000+ m√©moires
2. **Pr√©cision**: R√©sultats pertinents dans 85%+ des cas
3. **Fiabilit√©**: Z√©ro perte de donn√©es
4. **Maintenabilit√©**: Interface claire et document√©e

## üß™ Sc√©narios de test

### Test 1: Stockage d'une m√©moire
```gherkin
Given un Vector Store initialis√©
When je stocke une m√©moire avec du contenu
Then un embedding est g√©n√©r√© automatiquement
And la m√©moire est persist√©e avec son vecteur
And l'index de recherche est mis √† jour
```

### Test 2: Recherche s√©mantique basique
```gherkin
Given des m√©moires stock√©es sur diff√©rents sujets
When je recherche "probl√®me de performance"
Then les m√©moires sur l'optimisation sont retourn√©es
And les r√©sultats sont tri√©s par similarit√©
And le score de similarit√© est inclus
```

### Test 3: Recherche avec filtres
```gherkin
Given des m√©moires de diff√©rents types et projets
When je recherche avec des filtres de type et projet
Then seules les m√©moires correspondantes sont retourn√©es
And la similarit√© est calcul√©e uniquement sur ce sous-ensemble
```

### Test 4: Mise √† jour d'embedding
```gherkin
Given une m√©moire existante dans le store
When je mets √† jour son contenu
Then un nouvel embedding est g√©n√©r√©
And l'ancien embedding est remplac√©
And la recherche utilise le nouvel embedding
```

### Test 5: Performance avec volume
```gherkin
Given 1000 m√©moires stock√©es dans le Vector Store
When je lance une recherche s√©mantique
Then les r√©sultats sont retourn√©s en moins de 100ms
And la pr√©cision reste √©lev√©e
```

### Test 6: Persistance des donn√©es
```gherkin
Given des m√©moires stock√©es dans le Vector Store
When le syst√®me red√©marre
Then toutes les m√©moires et embeddings sont r√©cup√©r√©s
And les recherches fonctionnent imm√©diatement
```

## üìä M√©triques de succ√®s

### Performance
- G√©n√©ration d'embedding < 200ms par m√©moire
- Recherche < 100ms pour 1000 m√©moires
- Indexation < 500ms pour 100 nouvelles m√©moires

### Qualit√©
- Pr√©cision de recherche > 85%
- Rappel de recherche > 80%
- Z√©ro perte de donn√©es lors des red√©marrages

### Scalabilit√©
- Support de 10,000 m√©moires sans d√©gradation
- Utilisation m√©moire < 500MB pour 1000 m√©moires
- Temps d'indexation lin√©aire avec le volume

## üîÑ D√©pendances

### Techniques
- Mod√®le d'embedding (Sentence Transformers)
- Base de donn√©es vectorielle (Chroma/Qdrant)
- Biblioth√®que de calcul vectoriel (NumPy/TensorFlow.js)

### M√©tier
- **D√©pend de**: Task 001 (MCP Server) pour l'interface
- **Pr√©requis pour**: Task 005 (Recherche s√©mantique)

## üìÖ Estimation

**Complexit√©**: √âlev√©e
**Effort**: 4-6 jours
**Risques**:
- Performance des mod√®les d'embedding
- Gestion de la m√©moire pour gros volumes
- Compatibilit√© entre diff√©rents mod√®les d'embedding
- Optimisation des index vectoriels
